{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e63df7be-b9fd-46d4-b046-4390d33bc86a",
   "metadata": {},
   "source": [
    "# Dynamic Padding :- \n",
    "pad the sentences at the batch creation, to the length of the longest sentences , and this technique is called dynamic paddingpad the sentences at the batch creation, to the length of the longest sentences , and this technique is called dynamic padding\n",
    "\n",
    "* Advantages\n",
    " :- All the batches will have the smallest size possible\n",
    "* disadvantage\n",
    "  :-\n",
    "  Dynamic shapes don't work well on all accelerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8cdff9f-8315-493f-a2f3-d33f2eeabbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8236de7f-117c-4a6e-be92-c433fb793de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = load_dataset('glue',\"mrpc\")\n",
    "checkpoint = 'bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "303d28c8-efb0-4d00-b492-00143f7bdbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a tokenzer function which tokenize the given sentences\n",
    "def tokenize_function(ex):\n",
    "    return tokenizer(\n",
    "        ex['sentence1'],ex['sentence2'],padding=\"max_length\",truncation=True,max_length=128\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ee82d47-f688-45c5-9941-ffc47389ac9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fca32ad4c74023ada612476f2a1a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef82097b2a6446cb42710418fbec6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3940978c5ca42bb9593b866cc8ea37f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#applying the tokenizer functin\n",
    "tokenized_dataset = raw_dataset.map(tokenize_function,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be04ee4e-b14c-4532-9bc9-531a5636ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing preprocessing on tokenized dataset\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"idx\",\"sentence1\",\"sentence2\"])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\",\"labels\")\n",
    "tokenized_dataset = tokenized_dataset.with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "121feaac-62e9-4235-911c-0fc0fea3c757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can then use our dataset in a standard PYtorch DataLoader.\n",
    "#As expected we get batches of fixed shapes\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ac63f38-45d5-49d1-be62-8dc3405fa999",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_dataset[\"train\"],batch_size=16,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6c7b9d5-5541-4c1f-8789-272e4aed2962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128])\n",
      "torch.Size([16, 128])\n",
      "torch.Size([16, 128])\n",
      "torch.Size([16, 128])\n",
      "torch.Size([16, 128])\n",
      "torch.Size([16, 128])\n",
      "torch.Size([16, 128])\n"
     ]
    }
   ],
   "source": [
    "for step,batch in enumerate(train_dataloader):\n",
    "    print(batch['input_ids'].shape)\n",
    "    if step>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485c2ee-d37a-4c6b-85cb-2784b7c327f2",
   "metadata": {},
   "source": [
    "# To apply dynamic padding we postpone the padding in the preprocessing function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3a45efb-d12f-4515-a49c-9838b57b5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a33d42be-1578-40e1-8b30-ee19e72435a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = load_dataset('glue',\"mrpc\")\n",
    "checkpoint = 'bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6459bd5-ac2d-4664-97f5-f3bf08fdb6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a tokenzer function which tokenize the given sentences\n",
    "# here we remove the padding stufs as we dicucussed\n",
    "def tokenize_function(ex):\n",
    "    return tokenizer(\n",
    "        ex['sentence1'],ex['sentence2'],truncation=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbbf8357-b371-42fa-be44-4b03752cf12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094b9eccd92741b19131fb0b4f8cf2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41857e5d7fd142029da8b8ef08f150fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b076781784d6409c84137a8dd02a451d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#applying the tokenizer functin\n",
    "tokenized_dataset = raw_dataset.map(tokenize_function,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "487ba99a-bf9a-4410-8f6c-3d888942400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing preprocessing on tokenized dataset\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"idx\",\"sentence1\",\"sentence2\"])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\",\"labels\")\n",
    "tokenized_dataset = tokenized_dataset.with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8c08daf-8ce4-446a-9bf6-5b93b432f170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#each batch then has a different size, but there is no needless padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e3397ca-9231-4dfe-893c-477656782a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da2862bd-f9d3-4352-92d0-23de11c7d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset['train'],batch_size=16,shuffle=True,collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bf50b5d-d5dc-4b56-8f26-9f3ba86006e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 74])\n",
      "torch.Size([16, 63])\n",
      "torch.Size([16, 81])\n",
      "torch.Size([16, 86])\n",
      "torch.Size([16, 93])\n",
      "torch.Size([16, 86])\n",
      "torch.Size([16, 88])\n"
     ]
    }
   ],
   "source": [
    "# now we each batch shape is diffenet due to appication on dynamic padding\n",
    "for step,batch in enumerate(train_dataloader):\n",
    "    print(batch['input_ids'].shape)\n",
    "    if step>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9fa273-f55c-4b73-ae16-e7c5be5074c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
