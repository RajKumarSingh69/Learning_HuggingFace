{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c46360f-34fa-4f20-aae5-c0e21e3437e5",
   "metadata": {},
   "source": [
    "# Memory Mapping and Steaming\n",
    "* if you want to trian a model from scratch, you will need lot of data and their size is very huge\n",
    "* Datasets uses arraow and streaming to handle data at scale, it mean if a dataset is very hue and it can't able to fit into our memory then for handling this issue dataset library has steaming api to handle this\n",
    "* Arrow memory mapped format enables access to better than RAM dataset\n",
    "* Memory mapped files can be shared across multiple processes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28de18cf-4b41-4265-9d77-40a3f137230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f2a86-2786-4bb1-89f0-f70eb737da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = \"some remote location let say\"\n",
    "large_dataset = load_dataset(\"json\",data_files=data_files,spit='train')\n",
    "size_gb=large_dataset.dataset_size/(1024**3)\n",
    "print(f\"Dataset size(cache file) :{size_gb:.2f} GB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ded7de-2218-4583-96bc-dc152f2b668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading a dataset only uses a small amount of ram\n",
    "import psutil\n",
    "#process.memory_info is expressed in bytes , to convert megabyte\n",
    "print(f\"RAM used: {psutil.Process().memory_info().res/(1024*1024):.rf} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a659d-55cc-43bc-9fec-fb960f8ec239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This makes iterating on memory-mapped file blazing fast\n",
    "import timeit\n",
    "\n",
    "code_sipit = \"\"\"batch_size=1000\n",
    "for idx in rnage(0,len(large_dataset),batch)size):\n",
    "_= large_datset[idx:idx+batch_size]\n",
    "\n",
    "\"\"\"\n",
    "time=timeit.timeit(stmt=code_snipit,number=1,globals=globals())\n",
    "print(\n",
    "    f\"Iterated over {len(large_dataset)} example (about {size_gb:.1f} GB) in\",\n",
    "    f\"{time:1f}s, i.e.{size_gb/time\"3f}GB/d\")\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "707e56c3-c198-4bcb-bd68-44e0f4cde0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Streaming kets you process bigger than disk datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201edc98-67c3-45db-9ae2-6eb3380f4f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_dataset = load_dataset(\"json\",data_files=data_files,split='train',streaming=True)\n",
    "next(iter(large_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a761f773-7a0a-43ff-9904-0ca8c3b49243",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(larg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c0c94d-fe6b-40c6-980d-109725e969b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a3276d-7101-45d2-a993-874ab06ab3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db1118b-c6ff-4511-b0ef-e75da82b5190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce90d1f-ab43-40d9-83d5-3714dee1ada4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
