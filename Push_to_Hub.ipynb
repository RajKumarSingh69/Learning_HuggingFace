{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa5a5e7-eeb0-48cc-9e02-40a5642f4034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this we are going to see how we can push out model to the HuggingFace hub with code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d7f1c-2388-41a9-91a3-26468d70c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login() # thsi function helps us to loggig in our huggingFace account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "555a1312-3fca-4f5b-a3b8-465b92c8e7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09d0a9b943e487bb5816269731702aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/251k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e454808e95cc4fcc87c3500f82bd6a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/37.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80851628605498ebdd85ec821d59702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/37.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0cc5b2b20c4751b886acfa518d0b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf09816e0ce46abb5f9712e92e19f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea02ddc5f4d48e79baac2e9b08f8cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now code\n",
    "from datasets import load_dataset\n",
    "raw_dataset = load_dataset(\"glue\",\"cola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42362fdb-e53a-4e07-b2fa-a7934efae0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 8551\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1043\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1063\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eacdb313-bf61-49cd-a418-44c90e2045d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_checkpoint= \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d415715c-1c47-478f-9093-271a879d4497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5baaf499b5455aabe0ee3ee23824c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69873fde2d124c9a85b05d42e5d92e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25de69baa124960a6fd137cdc875b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(example):\n",
    "    return tokenizer(example['sentence'],truncation=True)\n",
    "tokenized_dataset = raw_dataset.map(preprocess_function,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e3fe54a-857b-468e-860c-720b2b902205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69a3f6d9-8c4d-4d92-995e-1c10a10993c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "300edf74-ba20-4929-98dc-d7c122f4a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_dataset(\"glue\",\"cola\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions,labels=eval_pred\n",
    "    predictions=np.argmax(predictions,axis=-1)\n",
    "    return metric.compute(predictions=predictions,references=lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e83861b3-16a5-4a8e-bff3-5ce81118bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "args = TrainingArguments(\n",
    "    \"bert-fine-tuned-cola\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0b92f4-70aa-46de-a0ef-cbc1080bc6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "trainer=Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b27f81-4c7e-4b6f-8dca-ba41a06f6109",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(\"end of training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a518b9-3410-4576-a3d4-be346341ac37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd5cd5f6-8d1c-408b-8326-92537645b32f",
   "metadata": {},
   "source": [
    "# Pushing components individauly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73fcd81-6646-448b-94b8-1e3e46a5253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name=\"bert-fine-tuned-cola\"\n",
    "model.psuh_to_hub(repo_name)\n",
    "tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03983c39-da2b-474c-93c7-72e345ce36b5",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db0d69cf-19b1-4c16-b9c8-15e5dcef39ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unacceptable', 'acceptable']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = raw_dataset['train'].features['label'].names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e294f63a-f576-4e12-88c7-c14b887bc201",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label = {str(i):lb1 for l ,lb1 in enumerate(label_names)}\n",
    "model.config.label2id = {lbl:str(i) for l ,lb1 in enumerate(label_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0828da0-66b6-44b0-b3d2-6b0a9bb4d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name=\"bert-fine-tuned-cola\"\n",
    "model.config.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b78d5f-c577-423b-bde0-533dbf4a0dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53c104-5258-4cd0-be39-b78d8749cc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89be0fe1-2722-4501-a47e-5fd35b6c6f43",
   "metadata": {},
   "source": [
    "# Push to Hub (Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166de935-6ee8-45af-afc8-1afbb16958f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first logging into your account\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa92c673-8383-4c74-b718-37989aec6d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 8551\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1043\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1063\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the datasets\n",
    "from datasets import load_dataset\n",
    "raw_dataset=load_dataset(\"glue\",\"cola\")\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a4377d7-2c5f-4686-9444-b83d4e0f332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc41e6ba-c83a-4fa2-871b-0e89ff3822dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9ee55da46945bdb6e7796f1a1c65f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91f8eaccc5f44c89d7860006073f8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b37d806808a44d8b1398e5cc27bb503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 8551\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1043\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1063\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_fucntion(example):\n",
    "    return tokenizer(example[\"sentence\"],truncation=True)\n",
    "tokenized_dataset = raw_dataset.map(preprocess_fucntion,batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4914611f-5004-473e-87cf-5dc88f25b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "collator = DataCollatorWithPadding(tokenizer=tokenizer,return_tensors='tf')\n",
    "\n",
    "train_dataset = tokenized_dataset['train'].to_tf_dataset(\n",
    "    columns=['attention_mask','input_ids','labels','token_type_ids'],\n",
    "    collate_fn=collator,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_dataset = tokenized_dataset['validation'].to_tf_dataset(\n",
    "    columns=['attention_mask','input_ids','labels','token_type_ids'],\n",
    "    collate_fn=collator,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f03ec094-cecb-4386-b9c6-6b0144aecdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#loading the model\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7d52392-b6bf-4473-b7dc-4fc70469890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamWeightDecay\n",
    "optimizer = AdamWeightDecay(2e-5,weight_decay_rate=0.01)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ad5280-a629-441f-8c2e-6b28a7a41bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PushToHubCallback\n",
    "callbacks = [PushToHubCallback(\"model_output/\",\n",
    "                               tokenizer=tokenizer,\n",
    "                               hub_model_id=\"bert-fine-tuned-cola\")\n",
    "model.fit(train_dataset,validation_dataset=validation_dataset,epochs=2,callbacks=callable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb421b9-8956-429a-a86d-62332bc94f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now push the model to the hub\n",
    "model.push_to_hub(\"bert-fine-tuned-cola\",commit_message=\"End of Traning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d1c3bb-a683-4127-ad27-97dc913e2bab",
   "metadata": {},
   "source": [
    "# Lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bce3437-4b6a-44a9-a4d5-04638b198c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unacceptable', 'acceptable']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = raw_dataset['train'].features['label'].names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7271c2-a812-4ef6-bb94-613997c1918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label = {str(i):lb1 for l ,lb1 in enumerate(label_names)}\n",
    "model.config.label2id = {lbl:str(i) for l ,lb1 in enumerate(label_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bafe923-7455-4e17-86f0-566c67649d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name=\"bert-fine-tuned-cola\"\n",
    "model.config.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90befe29-b135-4e14-b8e9-f1b72382fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Loading the pushed model\n",
    "loaded_model = TFAutoModelForSequenceClassification.from_pretrained(\"full repo path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e30eb2-8e6e-4ef2-8eab-c2e4ebdb82d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f10df-1756-4d62-9721-139b3e9f3f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bafe712-2ac7-43f1-bc42-3680a24443ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
