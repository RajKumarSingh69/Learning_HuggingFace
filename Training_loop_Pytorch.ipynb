{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b9dd6e-8664-408f-92b4-2cbefc477b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer,DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430b80f5-1d92-4a54-b22e-e3277b9d119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = load_dataset(\"glue\",\"mrpc\")\n",
    "checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e751eb45-7dd7-4b00-9b5a-83412185e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fucntion for tokinizing our imported data\n",
    "def tokenize_function(ex):\n",
    "    return tokenizer(ex['sentence1'],ex['sentence2'],truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be30c60-92c4-4ea5-8667-c2367a76e08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ac8f09d7b6461abe695e77e7c58466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004b758b0dd34e1ebd8eb4940a69c162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52971ceb431f48beac23823e5a641770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#now doing pre-processing\n",
    "tokenized_dataset = raw_dataset.map(tokenize_function,batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(['sentence1','sentence2','idx'])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\",\"labels\")\n",
    "tokenized_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77c508a6-0e00-4c72-92b0-b4faf5a82f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using dynamic padding concept\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "473f88bc-9253-4a8f-8cf4-03e44b83ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nwo we need to define the pytorch data loader\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38b4cbfc-89a7-4652-8647-0e671ac1f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are creating our data loaders\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset['train'],shuffle=True,batch_size=8,collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_dataset['validation'],batch_size=8,collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd560a72-519b-443f-8b31-87eabe5e0dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': torch.Size([8]), 'input_ids': torch.Size([8, 66]), 'token_type_ids': torch.Size([8, 66]), 'attention_mask': torch.Size([8, 66])}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "print({k:v.shape for k,v in batch.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95c580e1-6977-4f41-baea-d6d84ce1356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to create a model\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c0b928c-7c0f-4468-aa53-443a16608e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"bert-base-cased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint,num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a142972c-449e-43f2-bb05-fe127cccbbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6511, grad_fn=<NllLossBackward0>) torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**batch)\n",
    "print(outputs.loss,outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "007c6a1c-96ea-44b1-a70e-a20d18474555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the traing step is happening\n",
    "# the optimizer will be responsivle for doing the training updates to the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "072d267f-d1da-44e8-a71d-becf78c1df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8805a6-6bbc-469a-ad74-02b43c2fb75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2696f79-55f1-4c50-996a-1849dce0ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "#don't forget to zero our gradients once our optimizer step is done:\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67b2c11a-51cd-4b38-bfbe-1fc3213335c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for betting traing again we are going to introdce learing rate schedular\n",
    "# A learning rate schedular will update the optimizer's learining rate at each step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a2f6ba1-1e22-4f43-87fc-6b950cb3ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef23f58b-2317-4121-9245-53a9d9bcb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "num_traning_steps = num_epochs * len(train_dataset)\n",
    "lr_schedular = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_training_steps=0,\n",
    "    num_warmup_steps=num_traning_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0199a83c-9b07-478b-b5cb-f570f602e621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# now for taring we need gpu\n",
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a38797-49a8-4234-9d6e-917c134fa079",
   "metadata": {},
   "source": [
    "# now putting everythiing together and here is the training loop looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d5cb7df-00cf-4ad7-8a34-1c22804063b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a498500-11eb-47e9-972c-85ecde4a3bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = tqdm(range(num_training_setps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0437d6f6-d5fe-42f6-899c-ef8fcabdf584",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for each in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch ={k:v.to(device) for k,v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_schedualr.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c94d6f9-1a1e-40cf-98f7-60e81f93009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mow compute metrics\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb6b9c5-2d00-4772-bcdb-a8dc302028b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric=load_metric(\"glue\",\"mrpc\")\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch ={k:v.to(device) for k,v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs=model(**batch)\n",
    "\n",
    "    logits=outputs.logits\n",
    "    predictions=torch.argmax(logits,dim=-1)\n",
    "    metric.add_batch(predictions=predictions,references=batch['labels']\n",
    "metric.compute()\n",
    "# now this will show the accurcy and the f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d5c68-d3f0-44a6-af39-7371028809f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d194bdf8-fab8-4377-b4f2-98ab50fadcb2",
   "metadata": {},
   "source": [
    "# Supercharge our training loop with Accelerate\n",
    "we are going to use TrainerAPi for this purpose :- The TrainerApi can handle all those setups for you, but you lose control over your training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "831cd395-13df-4123-a045-c8ea6ae0ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4568e186-0a09-4ec3-9d0c-17640a24dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f3e40-d037-499f-a8d8-fa5414902a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,optimizer,trai_dataloader=accelerator.prepare(\n",
    "    model,optimizer,train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc532a5-6e41-4e27-86fe-8d690c087f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epochs in range(num_apochs):\n",
    "    outputs=model(**batch)\n",
    "    loss=outputs.loss\n",
    "    accelerator.backward(loss)\n",
    "\n",
    "    optimizer.step()\n",
    "    lr_schedualr.step()\n",
    "    optimizer.zero_grad()\n",
    "    progress_bar.update()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6595ab-5d45-4389-95a4-c2b2405e2f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accelerate also handles distributed evaluation\n",
    "metric=load_metric(\"glue\",\"mrpc\")\n",
    "model.eval()\n",
    "\n",
    "eval_dataloader=accelerator.prepare(eval_dataloader)\n",
    "for batch in eval_dataloader:\n",
    "    #batch ={k:v.to(device) for k,v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs=model(**batch)\n",
    "\n",
    "    logits=outputs.logits\n",
    "    predictions=torch.argmax(logits,dim=-1)\n",
    "    #metric.add_batch(predictions=predictions,references=batch['labels']\n",
    "    metric.add_batch(\n",
    "        predictions=accelerator.gather(predictions),references=accelerator.gather(batch['labels'])\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04270ef6-5583-4273-ad3f-82d10839e1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211dff71-82e8-4be1-be32-5d5ca468ae94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32330ca-a7ef-44d2-9fe5-9f5593fda110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
